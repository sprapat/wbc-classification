{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying White Blood Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "An important problem in blood diagnostics is classifying different types of blood cells. In this notebook, we will attempt to train a classifier to predict the type of a blood cell given a dyed picture of it.\n",
    "\n",
    "### Data\n",
    "\n",
    "We have 351 pictures of dyed white blood cells along with labels of what type of blood cell they are. Below is an example of each of the types of blood cells in our dataset.\n",
    "\n",
    "##### Basophil\n",
    "![Basophil](Basophil.jpg)\n",
    "\n",
    "#### Eosinophil\n",
    "![Eosinophil](Eosinophil.jpg)\n",
    "\n",
    "#### Lymphocyte\n",
    "![Lymphocyte](Lymphocyte.jpg)\n",
    "\n",
    "#### Monocyte\n",
    "![Monocyte](Monocyte.jpg)\n",
    "\n",
    "#### Neutrophil\n",
    "![Neutrophil](Neutrophil.jpg)\n",
    "\n",
    "### Methodology\n",
    "\n",
    "We use a simple LeNet architecture trained on 280 training samples with image augmentation. Our augmentation techniques include rotations, shifts, and zooms.\n",
    "\n",
    "We validate our results against 70 samples.\n",
    "\n",
    "### Results\n",
    "\n",
    "We obtain an accuracy of 93% on this validation set with the following confusion matrix:\n",
    "\n",
    "![Confusion Matrix](confusion_matrix.png)\n",
    "\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "I think these results show that it is possible to train a strong classifier for WBCs that can approach really strong accuracies with more and more data.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "It's hard to try and improve the results with so little validation data. Fixing one prediction here or there would lead to a big change in accuracy etc. The next steps should be to augment our training and test sets with further image augmentation techniques or just more real data.\n",
    "\n",
    "Here are some potential techniques to improve accuracy:\n",
    "\n",
    "* Use color thresholding to find the center of each WBC and crop the images to be centered around those areas.\n",
    "* Use VGG net etc. and retrain the last few layers.\n",
    "* Balance out the dataset through image augmentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7306431031ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Lambda\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import csv\n",
    "import cv2\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "epochs = 20\n",
    "# BASE_PATH = '/home/ec2-user/cell_classifier/'\n",
    "BASE_PATH = '../'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1., input_shape=(120, 160, 3), output_shape=(120, 160, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(120, 160, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_for_index(index):\n",
    "    PREFIX = 'images/BloodImage_'\n",
    "    num_zeros = 5 - len(index)\n",
    "    path = '0' * num_zeros + index\n",
    "    return PREFIX + path + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = csv.reader(open(BASE_PATH + 'labels.csv'))\n",
    "# skip the header\n",
    "next(reader)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for row in reader:\n",
    "    label = row[2]\n",
    "    if len(label) > 0 and label.find(',') == -1:\n",
    "        filename = get_filename_for_index(row[1])\n",
    "        img_file = cv2.imread(BASE_PATH + filename)\n",
    "        if img_file is not None:\n",
    "            img_file = scipy.misc.imresize(arr=img_file, size=(120, 160, 3))\n",
    "            img_arr = np.asarray(img_file)\n",
    "            img_arr = apply_color_mask(img_arr)\n",
    "            X.append(img_arr)\n",
    "            y.append(label)\n",
    "\n",
    "\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_y = encoder.transform(y)\n",
    "\n",
    "y = np_utils.to_categorical(encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = datagen.flow(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "validation_generator = datagen.flow(\n",
    "        X_test,\n",
    "        y_test,\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(X_train),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(X_test),\n",
    "    epochs=epochs)\n",
    "model.save_weights('mask_1.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.load_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicting on test data')\n",
    "y_pred = np.rint(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred_unencoded = np.argmax(y_pred, axis=1)\n",
    "y_test_unencoded = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(confusion_matrix(y_test_unencoded, y_pred_unencoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder.inverse_transform([0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eosinophils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eosinophils = np.where(y_pred[:,1] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eosinophils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"IS CORRECT?\", np.array_equal(y_test[11],y_pred[11]))\n",
    "print(y_test[11])\n",
    "print(y_pred[11])\n",
    "imshow(X_test[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"IS CORRECT?\", np.array_equal(y_test[11],y_pred[11]))\n",
    "print(y_test[15])\n",
    "print(y_pred[15])\n",
    "imshow(X_test[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"IS CORRECT?\", np.array_equal(y_test[11],y_pred[11]))\n",
    "print(y_test[16])\n",
    "print(y_pred[16])\n",
    "imshow(X_test[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"IS CORRECT?\", np.array_equal(y_test[11],y_pred[11]))\n",
    "print(y_test[11])\n",
    "print(y_pred[11])\n",
    "imshow(X_test[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lymphocytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lymphocytes = np.where(y_pred[:,2] == 1)\n",
    "print(lymphocytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IS CORRECT?\", np.array_equal(y_test[22],y_pred[22]))\n",
    "print(y_test[22])\n",
    "print(y_pred[22])\n",
    "imshow(X_test[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IS CORRECT?\", np.array_equal(y_test[22],y_pred[22]))\n",
    "print(y_test[32])\n",
    "print(y_pred[32])\n",
    "imshow(X_test[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IS CORRECT?\", np.array_equal(y_test[22],y_pred[22]))\n",
    "print(y_test[60])\n",
    "print(y_pred[60])\n",
    "imshow(X_test[60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monocytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monocytes = np.where(y_pred[:,3] == 1)\n",
    "print(monocytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IS CORRECT?\", np.array_equal(y_test[6],y_pred[6]))\n",
    "print(y_test[6])\n",
    "print(y_pred[6])\n",
    "imshow(X_test[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IS CORRECT?\", np.array_equal(y_test[28],y_pred[28]))\n",
    "print(y_test[28])\n",
    "print(y_pred[28])\n",
    "imshow(X_test[28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
